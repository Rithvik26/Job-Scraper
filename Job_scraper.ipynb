{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a fuction taking job title and location as its parameters for tailoring of search anytime using the corresponding jobtitle and location\n",
    "def load_indeed_jobs_div(job_title,location):\n",
    "    getVars = {'q' : job_title, 'l' : location, 'fromage' : 'last', 'sort' : 'date' }\n",
    "    url = ('https://in.indeed.com/jobs?' + urllib.parse.urlencode(getVars))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    job_soup = soup.find(id=\"resultsCol\")\n",
    "    return job_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting job details\n",
    "\n",
    "#Function for job title\n",
    "def extract_job_title_indeed(job_elem):\n",
    "    title_elem = job_elem.find('h2', class_='title')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    "\n",
    "#Function for Company name\n",
    "def extract_company_indeed(job_elem):\n",
    "    company_elem = job_elem.find('span', class_='company')\n",
    "    company = company_elem.text.strip()\n",
    "    return company\n",
    "\n",
    "#Function for Link for job details\n",
    "def extract_link_indeed(job_elem):\n",
    "    link = job_elem.find('a')['href']\n",
    "    link = 'https://www.indeed.co.in/'+link\n",
    "    return link\n",
    "\n",
    "#Function for date that job was listed\n",
    "def extract_date_indeed(job_elem):\n",
    "    date_elem = job_elem.find('span', class_='date')\n",
    "    date = date_elem.text.strip()\n",
    "    return date\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_elems for Iterating over the listed jobs that each job card was within a div \n",
    "job_soup=load_indeed_jobs_div('Software Engineer intern','Hyderabad')\n",
    "job_elems = job_soup.find_all('div', class_='jobsearch-SerpJobCard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I wanted to make my function generalisable, so that people could choose which characteristics they wanted to search for (out of job titles, companies, link and date listed)\n",
    "cols = []\n",
    "extracted_info = []\n",
    "desired_characs=['titles','companies']\n",
    "\n",
    "if 'titles' in desired_characs:\n",
    "    titles = []\n",
    "    cols.append('titles')\n",
    "    for job_elem in job_elems:\n",
    "        titles.append(extract_job_title_indeed(job_elem))\n",
    "    extracted_info.append(titles)         \n",
    "    \n",
    "if 'companies' in desired_characs:\n",
    "    companies = []\n",
    "    cols.append('companies')\n",
    "    for job_elem in job_elems:\n",
    "        companies.append(extract_company_indeed(job_elem))\n",
    "    extracted_info.append(companies)         \n",
    "    \n",
    "if 'links' in desired_characs:\n",
    "    links = []\n",
    "    cols.append('links')\n",
    "    for job_elem in job_elems:\n",
    "        links.append(extract_link_indeed(job_elem))\n",
    "    extracted_info.append(links)         \n",
    "    \n",
    "if 'date_listed' in desired_characs:\n",
    "    date_listed = []\n",
    "    cols.append('date_listed')\n",
    "    for job_elem in job_elems:\n",
    "        date_listed.append(extract_date_indeed(job_elem))\n",
    "    extracted_info.append(date_listed)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing into a dictionary jobs_list to export to any chosen format\n",
    "\n",
    "jobs_list={}\n",
    "\n",
    "for j in range(len(cols)):\n",
    "    jobs_list[cols[j]]=extracted_info[j]\n",
    "\n",
    "#number of records of listings of jobs\n",
    "num_listings = len(extracted_info[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles ['TD Advanced Modeling, Intern ( 6 Months )', 'UAV intern', 'Intern/ Associate Engineer / QA', 'Intern/ Associate Engineer / Cloud', 'Intern/ Associate Engineer / React Native', 'Success Agent', 'Student Intern- Flux', 'Success Engineer', 'Support Engineer', 'Associate Engineering Intern', 'SDE Intern', 'Salesforce Test Automation Developer', 'MS Engineer- L1', 'Senior ServiceNow Developer', 'Sr Validation Engineer']\n",
      "companies ['Micron', 'Wings Drones Academy - A dvision of Wings Aviation...', 'Mutual Mobile', 'Mutual Mobile', 'Mutual Mobile', 'Salesforce', 'Altair Engineering', 'Salesforce', 'Salesforce', 'Salesforce', 'ADCI HYD 13 SEZ', 'Salesforce', 'NTT Ltd', 'ServiceNow', 'Silicon Labs']\n"
     ]
    }
   ],
   "source": [
    "for i in jobs_list.keys():\n",
    "    print(i,jobs_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
